# -*- coding: utf-8 -*-
"""fcc_sms_text_classification_DubraskaS.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rBZ-sGwbJ_yX_ogypxNfSR4_Tc8Bq2V7
"""

# import libraries
try:
  # %tensorflow_version only exists in Colab.
  !pip install tf-nightly
except Exception:
  pass
import tensorflow as tf
import pandas as pd
from tensorflow import keras
!pip install tensorflow-datasets
import tensorflow_datasets as tfds
import numpy as np
import matplotlib.pyplot as plt

print(tf.__version__)

# get data files
!wget https://cdn.freecodecamp.org/project-data/sms/train-data.tsv
!wget https://cdn.freecodecamp.org/project-data/sms/valid-data.tsv

train_file_path = "train-data.tsv"
test_file_path = "valid-data.tsv"

# Print the file path for verification (optional)
print(f"Reading data from: {train_file_path}")

try:
  # Read the TSV data using pandas
  train_ = pd.read_csv(train_file_path, sep="\t", names=['class', 'sms'])
  print("Data read successfully!")
except FileNotFoundError:
  print(f"Error: File not found at {train_file_path}")

print(train_.head())  # Print the first few rows of the data

# Now for the test one
print(f"Reading data from: {test_file_path}")

try:
  # Read the TSV data using pandas
  test_ = pd.read_csv(test_file_path, sep="\t", names=['class', 'sms'])
  print("Data read successfully!")
except FileNotFoundError:
  print(f"Error: File not found at {test_file_path}")

print(test_.head())

# check target balance

train_['class'].value_counts(normalize = True).plot.bar()

"""## PREPROCESSING"""

#PREPROCESSING TEXT
import nltk
nltk.download('punkt')
nltk.download('stopwords')
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.stem import WordNetLemmatizer
nltk.download('wordnet')
import re

lemmatizer = WordNetLemmatizer()

def preprocessing(sms):

    words = word_tokenize(sms) #Tokenization
    #to Lowercase
    words = [word.lower() for word in words if word.isalnum()]
    #Remove Stopwords
    words = [word for word in words if word not in stopwords.words("english")]
    #Lemmatize
    words = [lemmatizer.lemmatize(word) for word in words]
    preprocessed = ' '.join(words)

    return preprocessed # Return the preprocessed text as a string


#Apply
train_['sms'] = [preprocessing(text) for text in train_['sms']]
test_['sms'] = [preprocessing(text) for text in test_['sms']]

train_.head()

#Shuffle datasets
train_ = train_.sample(frac=1, random_state=42)
test_ = test_.sample(frac=1, random_state=42)

#SPLIT DATASETS IN X AND Y
x_train = train_['sms']
y_train = train_['class']

x_test = test_['sms']
y_test = test_['class']

print(x_test[:5])

"""## FEATURE EXTRACTION"""

# Bag of Words

from sklearn.feature_extraction.text import CountVectorizer

cv = CountVectorizer()

X_train_cv = cv.fit_transform(x_train)

X_train_cv.shape

# transform X_test using CV

X_test_cv = cv.transform(x_test)

"""## MODEL BUILDING AND TESTING"""

from sklearn.naive_bayes import MultinomialNB

# Build a Gaussian Classifier
model = MultinomialNB()

# Model training
model.fit(X_train_cv, y_train)

# Predict Output
to_predict = X_test_cv  #already preprocessed!!!!
  #Now predict
predicted = model.predict(to_predict)  #Expects 2D array

predicted_proba = model.predict_proba(to_predict)[0]

#print("Actual Value:", y_test[453])
#print("Predicted Value:", predicted[0])
print(predicted)

# confusion matrix

from sklearn import metrics

CM = metrics.confusion_matrix(y_test, predicted)

cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = CM, display_labels = ['ham', 'spam'])

cm_display.plot()
plt.show()

"""## NOW PREDICTING"""

# function to predict messages based on model
# (should return list containing prediction and label, ex. [0.008318834938108921, 'ham'])
def predict_message(pred_text):
  # Preprocess the text
  processed_text = preprocessing(pred_text)

  # Convert the preprocessed text to a matrix given our 'bag of words'
  new_message = np.array([processed_text])  # Convert to a 2D array for prediction
  new_message_cv = cv.transform(new_message)  # Convert tomatrix

  # Predict the label and probability
  predicted_label = model.predict(new_message_cv)[0]
  predicted_proba = model.predict_proba(new_message_cv)[0]  # Probability for the predicted class

  return [predicted_proba[0], predicted_label]

# Test
text_ex = "How are you?."
prediction = predict_message(text_ex)
print(prediction)

# Run this cell to test your function and model. Do not modify contents.
def test_predictions():
  test_messages = ["how are you doing today",
                   "sale today! to stop texts call 98912460324",
                   "i dont want to go. can we try it a different day? available sat",
                   "our new mobile video service is live. just install on your phone to start watching.",
                   "you have won Â£1000 cash! call to claim your prize.",
                   "i'll bring it tomorrow. don't forget the milk.",
                   "wow, is your arm alright. that happened to me one time too"
                  ]

  test_answers = ["ham", "spam", "ham", "spam", "spam", "ham", "ham"]
  passed = True

  for msg, ans in zip(test_messages, test_answers):
    prediction = predict_message(msg)
    if prediction[1] != ans:
      passed = False

  if passed:
    print("You passed the challenge. Great job!")
  else:
    print("You haven't passed yet. Keep trying.")

test_predictions()